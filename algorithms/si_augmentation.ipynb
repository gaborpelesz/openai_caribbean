{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-08 13:49:57--  https://docs.google.com/uc?export=download&confirm=3Krg&id=1MKkipZP0knNNm_6EO9jRshxAo3Du1Hom\n",
      "Resolving docs.google.com (docs.google.com)... 172.217.20.14, 2a00:1450:400d:805::200e\n",
      "Connecting to docs.google.com (docs.google.com)|172.217.20.14|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://doc-08-24-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/mjl8egm51559spsap78q8q3cm9g5tf2s/1575806400000/17506844314399870089/*/1MKkipZP0knNNm_6EO9jRshxAo3Du1Hom?e=download [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2019-12-08 13:49:57--  https://doc-08-24-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/mjl8egm51559spsap78q8q3cm9g5tf2s/1575806400000/17506844314399870089/*/1MKkipZP0knNNm_6EO9jRshxAo3Du1Hom?e=download\n",
      "Resolving doc-08-24-docs.googleusercontent.com (doc-08-24-docs.googleusercontent.com)... 216.58.214.193, 2a00:1450:400d:802::2001\n",
      "Connecting to doc-08-24-docs.googleusercontent.com (doc-08-24-docs.googleusercontent.com)|216.58.214.193|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/zip]\n",
      "Saving to: ‘data.zip’\n",
      "\n",
      "data.zip                [  <=>               ] 779,49M  12,8MB/s    in 62s     \n",
      "\n",
      "2019-12-08 13:51:00 (12,6 MB/s) - ‘data.zip’ saved [817354993]\n",
      "\n",
      "The extraction of the images can take some time...\n",
      "Extraction done\n"
     ]
    }
   ],
   "source": [
    "import zipfile \n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1MKkipZP0knNNm_6EO9jRshxAo3Du1Hom' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1MKkipZP0knNNm_6EO9jRshxAo3Du1Hom\" -O data.zip && rm -rf /tmp/cookies.txt\n",
    "\n",
    "with zipfile.ZipFile('./data.zip', 'r') as zip_ref:\n",
    "        print('The extraction of the images can take some time...')\n",
    "        zip_ref.extractall('./')\n",
    "        print('Extraction done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the directories\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math, random\n",
    "import shutil\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "train = \"./cleaned_data/train/\"\n",
    "validation = \"./cleaned_data/validation/\"\n",
    "\n",
    "aug_train = \"./augmented_data/train\"\n",
    "aug_validation = \"./augmented_data/validation\"\n",
    "\n",
    "try:\n",
    "    categories = os.listdir(train)\n",
    "    for c in categories:\n",
    "        os.makedirs(os.path.join(aug_train,c))\n",
    "        os.makedirs(os.path.join(aug_validation,c))\n",
    "except OSError:\n",
    "    print (\"Necessary directories already exist\")\n",
    "else:\n",
    "    print (\"Successfully created the directories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation of ['concrete_cement', 'healthy_metal', 'incomplete', 'irregular_metal', 'other'] classes has begun. It may take some time...\n",
      "Squared image augmentation for image class concrete_cement with 1254 image(s)\n",
      "Copying 1834 image(s) for class healthy_metal\n",
      "Squared image augmentation for image class incomplete with 1517 image(s)\n",
      "Copying 1834 image(s) for class irregular_metal\n",
      "Squared image augmentation for image class other with 1773 image(s)\n",
      "Image augmentation done!\n"
     ]
    }
   ],
   "source": [
    "def si_augment(path, to_where, datagen, over_add=0, over_perc=0, max_corr=False):\n",
    "    #get all categories from path\n",
    "    categories = os.listdir(path)\n",
    "    print(\"Augmentation of\",categories, \"classes has begun. It may take some time...\")\n",
    "    #number of images in each category\n",
    "    image_nums = [len([name for name in os.listdir(data)]) \n",
    "                  for data in [path+cat for cat in categories]]\n",
    "    #what would be the ideal amount of image for each categories\n",
    "    if not max_corr:\n",
    "        idealcount = (math.ceil(sum(image_nums)/len(categories))+over_add)*(1+over_perc)\n",
    "    else:\n",
    "        idealcount = math.ceil(sum(image_nums)/len(categories))+math.ceil((max(image_nums)*0.15))\n",
    "    #how many image is missing for the ideal number\n",
    "    to_gener = [abs(num-idealcount) for num in image_nums]\n",
    "    where = 0\n",
    "    for cat in categories:\n",
    "        #if we have less image then needed we need to generate\n",
    "        if idealcount > image_nums[where]:\n",
    "            #lets calculate how many copy needed for every image in the given category\n",
    "            #estim_num = math.ceil(to_gener[where]/image_nums[where])\n",
    "            print(\"Squared image augmentation for image class\",\n",
    "                  cat, \"with\", to_gener[where],\"image(s)\")\n",
    "            #from where we load the images\n",
    "            src = os.path.join(path,cat)\n",
    "            images = os.listdir(src)\n",
    "            save_dir = os.path.join(to_where,cat)\n",
    "            #IMPORTANT!!! since the image generator tries to avoid duplication of images\n",
    "            #it will not allow us to create two images that are the same (even by random)\n",
    "            #we have to generate until there is the right amount of pictures\n",
    "            while (len([name for name in os.listdir(save_dir)])!=to_gener[where]):\n",
    "                img = load_img(os.path.join(src, random.choice(images)))\n",
    "                x = img_to_array(img)\n",
    "                x = x.reshape((1,) + x.shape)\n",
    "                x.shape\n",
    "                gen_img = datagen.flow(x,\n",
    "                                   batch_size=1,\n",
    "                                   save_to_dir=save_dir,\n",
    "                                   save_prefix='aug', \n",
    "                                   save_format='png')\n",
    "                for x in gen_img:\n",
    "                    break\n",
    "            #after generating the necessary images, let's copy the original ones\n",
    "            for image in images:\n",
    "                full_file_name = os.path.join(src, image)\n",
    "                shutil.copy(full_file_name, save_dir)\n",
    "        #if there is more image then needed \n",
    "        #we copy the ideal amount of image to the destination folder\n",
    "        else:\n",
    "            print(\"Copying\", idealcount, \"image(s) for class\", cat)\n",
    "            for k in range(idealcount):\n",
    "                which_img = os.path.join(path,cat,os.listdir(os.path.join(path,cat))[k])\n",
    "                aug_img = os.path.join(to_where,cat,os.listdir(os.path.join(path,cat))[k])\n",
    "                shutil.copyfile(which_img, aug_img)\n",
    "        where+=1\n",
    "    print(\"Image augmentation done!\")\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=40,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode='nearest')\n",
    "\n",
    "si_augment(train, aug_train, datagen, max_corr=True)\n",
    "#si_augment(validation, aug_validation, datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1834\n",
      "1834\n",
      "1834\n"
     ]
    }
   ],
   "source": [
    "#image_nums = [len([name for name in os.listdir(data)]) \n",
    "#                  for data in [train+cat for cat in categories]]\n",
    "#idealcount = math.ceil(sum(image_nums)/len(categories))+math.ceil((max(image_nums)*0.15))\n",
    "#print(idealcount)\n",
    "\n",
    "print(len(os.listdir(os.path.join(aug_train,categories[0]))))\n",
    "print(len(os.listdir(os.path.join(aug_train,categories[2]))))\n",
    "print(len(os.listdir(os.path.join(aug_train,categories[4]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "paths = [train, validation]\n",
    "sizes = []\n",
    "for p in paths:\n",
    "    for cat in categories:\n",
    "        location = os.path.join(p,cat)\n",
    "        for file in os.listdir(location):\n",
    "            im = Image.open(os.path.join(location,file))\n",
    "            sizes.append(im.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233.03112233528933"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sizes = np.array(sizes)\n",
    "np.std(sizes)\n",
    "np.mean(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[580, 3252, 318, 2521, 62]\n",
      "./cleaned_data/concrete_cement done\n",
      "./cleaned_data/healthy_metal done\n",
      "./cleaned_data/incomplete done\n",
      "./cleaned_data/irregular_metal done\n",
      "./cleaned_data/other done\n"
     ]
    }
   ],
   "source": [
    "paths = [os.path.join('./cleaned_data',p) for p in os.listdir('./cleaned_data')]\n",
    "numbers = [math.ceil(len(os.listdir(x))/2) for x in paths]\n",
    "categories = ['concrete_cement','healthy_metal','incomplete','irregular_metal','other']\n",
    "where = 0\n",
    "print(numbers)\n",
    "for p in paths:\n",
    "    counter = 0\n",
    "    for file in os.listdir(paths[where]):\n",
    "        filename = os.path.join(p,file)\n",
    "        halfname = os.path.join(\"./halfed\",categories[where],file)\n",
    "        shutil.copyfile(filename, halfname)\n",
    "        counter+=1\n",
    "        if counter is numbers[where]:\n",
    "            break\n",
    "    counter = 0\n",
    "    for file in os.listdir(paths[where]):\n",
    "        filename = os.path.join(p,file)\n",
    "        os.remove(filename)\n",
    "        counter+=1\n",
    "        if counter is numbers[where]:\n",
    "            break\n",
    "    where += 1\n",
    "    print(p, \"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
